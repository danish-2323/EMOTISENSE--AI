# EMOTISENSE AI ğŸ§ 

**Multimodal Emotion Recognition using Audio + Face**

A real-time emotion monitoring system that combines facial emotion detection and audio stress analysis to provide comprehensive emotional insights.

---

## ğŸš€ Quick Start

Run the application in **1 command**:

```bash
# Install dependencies and run
pip install -r requirements.txt && streamlit run app.py
The application will open in your browser at http://localhost:8501

ğŸ“ Project Structure
bash
Copy code
EMOTISENSE-AI/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                  # Configuration settings
â”‚   â”œâ”€â”€ utils.py                   # Utility functions
â”‚   â”œâ”€â”€ webcam/
â”‚   â”‚   â”œâ”€â”€ camera.py              # Camera capture
â”‚   â”‚   â””â”€â”€ face_emotion.py        # Face emotion detection
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ mic_capture.py         # Microphone capture
â”‚   â”‚   â””â”€â”€ audio_emotion.py       # Audio stress analysis
â”‚   â”œâ”€â”€ fusion/
â”‚   â”‚   â””â”€â”€ fusion_engine.py       # Multimodal fusion logic
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ ui_components.py       # UI components
â”‚   â”‚   â””â”€â”€ plots.py               # Visualization charts
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”œâ”€â”€ session_logger.py      # Session logging
â”‚   â”‚   â””â”€â”€ report_generator.py    # PDF report generation
â”‚   â”œâ”€â”€ fallback/
â”‚   â”‚   â””â”€â”€ rule_based.py          # Simulation / fallback mode
â”‚   â””â”€â”€ analytics/
â”‚       â”œâ”€â”€ session_insights.py    # Session intelligence & metrics
â”‚       â””â”€â”€ feedback_engine.py     # Rule-based feedback generation
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ session_logs/              # Session CSV files
â”‚   â”œâ”€â”€ reports/                   # Generated PDF reports
â”‚   â””â”€â”€ snapshots/                 # Auto-captured screenshots
ğŸ¯ Features
Core Functionality
Real-time Face Emotion Detection (happy, sad, angry, fear, surprise, neutral)

Audio Stress Analysis from microphone input

Multimodal Fusion Engine combining face and audio signals

Live Dashboard with real-time metrics and alerts

Session Logging with CSV export

PDF Report Generation with insights and recommendations

ğŸ†• Advanced Intelligence Features
Automatic Screenshot Capture on:

Extreme stress peaks

Extreme happiness moments

Continuous distraction

Emotion Timeline Analysis

Top Critical Moments Detection

Emotion Stability Score

Recovery Speed Measurement after stress spikes

Session Quality Score (0â€“100)

Attention Span Estimation

Session Risk Indicator (Low / Medium / High)

Dashboard Tabs
Live Dashboard â€“ Real-time video feed, emotion metrics, stress gauge, alerts

Session Report â€“ Analytics, insights, and export options

Screenshot Gallery â€“ Captured moments with timestamps & reasons

About â€“ Project overview and technology stack

Fallback & Safety Features
Simulation Mode (works without camera/microphone)

Hardware Failure Handling

Manual â€œMark Important Momentâ€ Button

Privacy-first Local Execution

Graceful Error Handling

ğŸ› ï¸ Technology Stack
Frontend: Streamlit

Computer Vision: OpenCV, FER

Audio Processing: sounddevice, librosa

Data Analysis: pandas, numpy

Visualization: plotly

Reports: reportlab

Backup Detection: DeepFace (fallback)

ğŸ“Š Metrics Provided
Primary Metrics
Stress Level (0â€“1)

Engagement (0â€“1)

Confidence (0â€“1)

Confusion (0â€“1)

Emotional States
Stressed, Engaged, Calm, Positive, Negative, Neutral

Audio Features
RMS Energy

Zero Crossing Rate

MFCC Coefficients

Spectral Centroid

ğŸ® Usage Instructions
Starting a Session
Run streamlit run app.py

Click Start Session

Allow camera and microphone permissions

Monitor emotions live on dashboard

Simulation Mode
Enable Simulation Mode if hardware is unavailable

Generates realistic emotion patterns

Ideal for demos and testing

Reports & Evidence
Stop session â†’ View analytics

Export CSV logs

Generate PDF reports

Review auto-captured screenshots

ğŸ”§ Configuration
Key settings in src/config.py:

python
Copy code
AUDIO_SAMPLE_RATE = 16000
AUDIO_CHUNK_DURATION = 2.0

VIDEO_WIDTH = 640
VIDEO_HEIGHT = 480

STRESS_THRESHOLD = 0.7
ALERT_DURATION = 5

FACE_WEIGHT = 0.6
AUDIO_WEIGHT = 0.4
ğŸš¨ Alerts & Monitoring
High Stress Alert (sustained)

Emotion Heat Indicator (Green â†’ Red)

Real-time Emotion Timeline

Focus Status Badge

ğŸ”„ Fallback Mechanisms
Camera failure â†’ simulated face emotions

Microphone failure â†’ simulated audio stress

Library issues â†’ default safe values

Full demo mode without hardware

ğŸ“ License
MIT License

ğŸ‘¨â€ğŸ’» Author
Danish â€” B.Tech Artificial Intelligence and Data Science

Hackathon Project: SRM IST Ã— NOOBTRON â€” NOOB HACKFEST

ğŸ‘¥ Team Members â€” PRIMELOGIX
Danish M â€” AI/ML Developer & Integration
Implemented the emotion pipeline, fusion logic, analytics engine, and system integration.

Chidarth H â€” UI/UX & Dashboard Support
Contributed to dashboard design, layout structure, and user interaction flow.

Deepban T â€” Research & Feature Design
Conducted problem research, use-case analysis, and feature ideation.

Jothik Rithin Bio J â€” Testing & Validation
Tested system workflows, edge cases, and improved demo reliability.

Deepak T A â€” Documentation & Presentation
Supported README preparation, pitch structuring, and submission formatting.

Built for hackathons, designed for impact. ğŸš€
